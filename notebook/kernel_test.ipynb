{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>    requirejs.config({\n",
       "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "        paths: {'vega': 'https://cdn.jsdelivr.net/npm/vega@v5.4.0?noext', 'vega-lib': 'https://cdn.jsdelivr.net/npm/vega-lib?noext', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@v3.3.0?noext', 'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@3?noext'}\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import altair as alt\n",
    "from altair.vega import v5\n",
    "from IPython.display import HTML\n",
    "\n",
    "# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
    "def prepare_altair():\n",
    "    \"\"\"\n",
    "    Helper function to prepare altair for working.\n",
    "    \"\"\"\n",
    "\n",
    "    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n",
    "    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "    noext = \"?noext\"\n",
    "    \n",
    "    paths = {\n",
    "        'vega': vega_url + noext,\n",
    "        'vega-lib': vega_lib_url + noext,\n",
    "        'vega-lite': vega_lite_url + noext,\n",
    "        'vega-embed': vega_embed_url + noext\n",
    "    }\n",
    "    \n",
    "    workaround = f\"\"\"    requirejs.config({{\n",
    "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "        paths: {paths}\n",
    "    }});\n",
    "    \"\"\"\n",
    "    \n",
    "    return workaround\n",
    "    \n",
    "\n",
    "def add_autoincrement(render_func):\n",
    "    # Keep track of unique <div/> IDs\n",
    "    cache = {}\n",
    "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "        if autoincrement:\n",
    "            if id in cache:\n",
    "                counter = 1 + cache[id]\n",
    "                cache[id] = counter\n",
    "            else:\n",
    "                cache[id] = 0\n",
    "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "        else:\n",
    "            if id not in cache:\n",
    "                cache[id] = 0\n",
    "            actual_id = id\n",
    "        return render_func(chart, id=actual_id)\n",
    "    # Cache will stay outside and \n",
    "    return wrapped\n",
    "           \n",
    "\n",
    "@add_autoincrement\n",
    "def render(chart, id=\"vega-chart\"):\n",
    "    \"\"\"\n",
    "    Helper function to plot altair visualizations.\n",
    "    \"\"\"\n",
    "    chart_str = \"\"\"\n",
    "    <div id=\"{id}\"></div><script>\n",
    "    require([\"vega-embed\"], function(vg_embed) {{\n",
    "        const spec = {chart};     \n",
    "        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "        console.log(\"anything?\");\n",
    "    }});\n",
    "    console.log(\"really...anything?\");\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    return HTML(\n",
    "        chart_str.format(\n",
    "            id=id,\n",
    "            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "    \n",
    "\n",
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def eval_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast auc eval function for lgb.\n",
    "    \"\"\"\n",
    "    return 'auc', fast_auc(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "    \n",
    "\n",
    "def train_model_regression(X, X_test, y, params, folds=None, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    splits = folds.split(X) if splits is None else splits\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        if verbose:\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "\n",
    "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual', n_jobs=-1):\n",
    "    \"\"\"\n",
    "    A function to train a variety of classification models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    if averaging == 'usual':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "        \n",
    "    elif averaging == 'rank':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        if averaging == 'usual':\n",
    "            \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "            \n",
    "            prediction += y_pred.reshape(-1, 1)\n",
    "\n",
    "        elif averaging == 'rank':\n",
    "                                  \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "                                  \n",
    "            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "            result_dict['top_columns'] = cols\n",
    "        \n",
    "    return result_dict\n",
    "\n",
    "# setting up altair\n",
    "workaround = prepare_altair()\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround,\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../input/'\n",
    "train_identity = pd.read_csv(f'{folder_path}train_identity.csv')\n",
    "train_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\n",
    "test_identity = pd.read_csv(f'{folder_path}test_identity.csv')\n",
    "test_transaction = pd.read_csv(f'{folder_path}test_transaction.csv')\n",
    "sub = pd.read_csv(f'{folder_path}sample_submission.csv')\n",
    "# let's combine the data and work with the whole dataset\n",
    "train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 590540 rows and 434 columns.\n",
      "Test dataset has 506691 rows and 433 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "one_value_cols == one_value_cols_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns in train dataset with one unique value.\n",
      "There are 1 columns in test dataset with one unique value.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(one_value_cols)} columns in train dataset with one unique value.')\n",
    "print(f'There are {len(one_value_cols_test)} columns in test dataset with one unique value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 414 columns in train dataset with missing values.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {train.isnull().any().sum()} columns in train dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/01017387/anaconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:754: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/Users/01017387/anaconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:755: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['id_01'], bins=77);\n",
    "plt.title('Distribution of id_01 variable');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     0.887689\n",
       " 0.0    0.108211\n",
       " 1.0    0.001461\n",
       " 3.0    0.001131\n",
       " 2.0    0.000713\n",
       "Name: id_03, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id_03'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN            0.761273\n",
       " 100.000000    0.225492\n",
       " 95.080002     0.002085\n",
       " 95.160004     0.001277\n",
       " 97.120003     0.000745\n",
       "Name: id_11, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id_11'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['id_07']);\n",
    "plt.title('Distribution of id_07 variable');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_to_mean_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_mean_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "train['TransactionAmt_to_std_card1'] = train['TransactionAmt'] / train.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "train['TransactionAmt_to_std_card4'] = train['TransactionAmt'] / train.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "test['TransactionAmt_to_mean_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_mean_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('mean')\n",
    "test['TransactionAmt_to_std_card1'] = test['TransactionAmt'] / test.groupby(['card1'])['TransactionAmt'].transform('std')\n",
    "test['TransactionAmt_to_std_card4'] = test['TransactionAmt'] / test.groupby(['card4'])['TransactionAmt'].transform('std')\n",
    "\n",
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_mean_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_std_card4'] = train['id_02'] / train.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_mean_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_std_card4'] = test['id_02'] / test.groupby(['card4'])['id_02'].transform('std')\n",
    "\n",
    "train['D15_to_mean_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_card1'] = train['D15'] / train.groupby(['card1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_card1'] = test['D15'] / test.groupby(['card1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "train['D15_to_mean_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('mean')\n",
    "train['D15_to_mean_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('mean')\n",
    "train['D15_to_std_addr1'] = train['D15'] / train.groupby(['addr1'])['D15'].transform('std')\n",
    "train['D15_to_std_card4'] = train['D15'] / train.groupby(['card4'])['D15'].transform('std')\n",
    "\n",
    "test['D15_to_mean_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('mean')\n",
    "test['D15_to_mean_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('mean')\n",
    "test['D15_to_std_addr1'] = test['D15'] / test.groupby(['addr1'])['D15'].transform('std')\n",
    "test['D15_to_std_card4'] = test['D15'] / test.groupby(['card4'])['D15'].transform('std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['P_emaildomain'].str.split('.', expand=True)\n",
    "train[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['R_emaildomain'].str.split('.', expand=True)\n",
    "test[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['P_emaildomain'].str.split('.', expand=True)\n",
    "test[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['R_emaildomain'].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols+ one_value_cols_test))\n",
    "cols_to_drop.remove('isFraud')\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29',\n",
    "            'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'ProductCD', 'card4', 'card6', 'M4','P_emaildomain',\n",
    "            'R_emaildomain', 'card1', 'card2', 'card3',  'card5', 'addr1', 'addr2', 'M1', 'M2', 'M3', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "            'P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']\n",
    "for col in cat_cols:\n",
    "    if col in train.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "X_test = test.sort_values('TransactionDT').drop(['TransactionDT', 'TransactionID'], axis=1)\n",
    "del train\n",
    "test = test[[\"TransactionDT\", 'TransactionID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by https://www.kaggle.com/dimartinot\n",
    "def clean_inf_nan(df):\n",
    "    return df.replace([np.inf, -np.inf], np.nan)   \n",
    "\n",
    "# Cleaning infinite values to NaN\n",
    "X = clean_inf_nan(X)\n",
    "X_test = clean_inf_nan(X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "folds = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Mon Aug  5 04:22:13 2019\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 256,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': 13,\n",
    "          'learning_rate': 0.03,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 3,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 0.9,\n",
    "          #'categorical_feature': cat_cols\n",
    "         }\n",
    "result_dict_lgb = train_model_classification(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='auc', plot_feature_importance=True,\n",
    "                                                      verbose=500, early_stopping_rounds=200, n_estimators=5000, averaging='usual', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values('TransactionDT')\n",
    "test['prediction'] = result_dict_lgb['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['isFraud'] = pd.merge(sub, test, on='TransactionID')['prediction']\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_dict_lgb['oof']).to_csv('lgb_oof.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
